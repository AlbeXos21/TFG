{
  "best_global_step": null,
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 0.010666666666666666,
  "eval_steps": 500,
  "global_step": 60,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.00017777777777777779,
      "grad_norm": 25.068880081176758,
      "learning_rate": 4e-05,
      "loss": 14.5781,
      "step": 1
    },
    {
      "epoch": 0.00035555555555555557,
      "grad_norm": 20.270633697509766,
      "learning_rate": 8e-05,
      "loss": 13.5227,
      "step": 2
    },
    {
      "epoch": 0.0005333333333333334,
      "grad_norm": 23.03067970275879,
      "learning_rate": 0.00012,
      "loss": 13.3704,
      "step": 3
    },
    {
      "epoch": 0.0007111111111111111,
      "grad_norm": 24.666858673095703,
      "learning_rate": 0.00016,
      "loss": 13.0045,
      "step": 4
    },
    {
      "epoch": 0.0008888888888888889,
      "grad_norm": 26.562255859375,
      "learning_rate": 0.0002,
      "loss": 9.8438,
      "step": 5
    },
    {
      "epoch": 0.0010666666666666667,
      "grad_norm": 15.673493385314941,
      "learning_rate": 0.00019636363636363636,
      "loss": 5.4958,
      "step": 6
    },
    {
      "epoch": 0.0012444444444444445,
      "grad_norm": 8.610888481140137,
      "learning_rate": 0.00019272727272727274,
      "loss": 3.8334,
      "step": 7
    },
    {
      "epoch": 0.0014222222222222223,
      "grad_norm": 6.181746006011963,
      "learning_rate": 0.0001890909090909091,
      "loss": 1.4947,
      "step": 8
    },
    {
      "epoch": 0.0016,
      "grad_norm": 4.776435852050781,
      "learning_rate": 0.00018545454545454545,
      "loss": 1.7894,
      "step": 9
    },
    {
      "epoch": 0.0017777777777777779,
      "grad_norm": 3.3676834106445312,
      "learning_rate": 0.00018181818181818183,
      "loss": 1.597,
      "step": 10
    },
    {
      "epoch": 0.0019555555555555554,
      "grad_norm": 2.8408045768737793,
      "learning_rate": 0.0001781818181818182,
      "loss": 1.1513,
      "step": 11
    },
    {
      "epoch": 0.0021333333333333334,
      "grad_norm": 3.3746511936187744,
      "learning_rate": 0.00017454545454545454,
      "loss": 1.2511,
      "step": 12
    },
    {
      "epoch": 0.002311111111111111,
      "grad_norm": 1.688988208770752,
      "learning_rate": 0.0001709090909090909,
      "loss": 1.1848,
      "step": 13
    },
    {
      "epoch": 0.002488888888888889,
      "grad_norm": 2.153036117553711,
      "learning_rate": 0.00016727272727272728,
      "loss": 1.0988,
      "step": 14
    },
    {
      "epoch": 0.0026666666666666666,
      "grad_norm": 2.7101569175720215,
      "learning_rate": 0.00016363636363636366,
      "loss": 0.9015,
      "step": 15
    },
    {
      "epoch": 0.0028444444444444446,
      "grad_norm": 3.1279489994049072,
      "learning_rate": 0.00016,
      "loss": 0.9528,
      "step": 16
    },
    {
      "epoch": 0.003022222222222222,
      "grad_norm": 2.411085367202759,
      "learning_rate": 0.00015636363636363637,
      "loss": 0.74,
      "step": 17
    },
    {
      "epoch": 0.0032,
      "grad_norm": 2.6790359020233154,
      "learning_rate": 0.00015272727272727275,
      "loss": 0.9214,
      "step": 18
    },
    {
      "epoch": 0.0033777777777777777,
      "grad_norm": 2.5781898498535156,
      "learning_rate": 0.0001490909090909091,
      "loss": 0.6289,
      "step": 19
    },
    {
      "epoch": 0.0035555555555555557,
      "grad_norm": 3.377880334854126,
      "learning_rate": 0.00014545454545454546,
      "loss": 0.658,
      "step": 20
    },
    {
      "epoch": 0.0037333333333333333,
      "grad_norm": 5.427354335784912,
      "learning_rate": 0.00014181818181818184,
      "loss": 1.2877,
      "step": 21
    },
    {
      "epoch": 0.003911111111111111,
      "grad_norm": 1.6641689538955688,
      "learning_rate": 0.0001381818181818182,
      "loss": 0.4893,
      "step": 22
    },
    {
      "epoch": 0.004088888888888889,
      "grad_norm": 4.383313179016113,
      "learning_rate": 0.00013454545454545455,
      "loss": 0.574,
      "step": 23
    },
    {
      "epoch": 0.004266666666666667,
      "grad_norm": 3.8261959552764893,
      "learning_rate": 0.00013090909090909093,
      "loss": 0.7558,
      "step": 24
    },
    {
      "epoch": 0.0044444444444444444,
      "grad_norm": 5.033674240112305,
      "learning_rate": 0.00012727272727272728,
      "loss": 0.8252,
      "step": 25
    },
    {
      "epoch": 0.004622222222222222,
      "grad_norm": 5.289637088775635,
      "learning_rate": 0.00012363636363636364,
      "loss": 0.5608,
      "step": 26
    },
    {
      "epoch": 0.0048,
      "grad_norm": 5.848053932189941,
      "learning_rate": 0.00012,
      "loss": 1.1395,
      "step": 27
    },
    {
      "epoch": 0.004977777777777778,
      "grad_norm": 6.089446544647217,
      "learning_rate": 0.00011636363636363636,
      "loss": 1.1102,
      "step": 28
    },
    {
      "epoch": 0.005155555555555556,
      "grad_norm": 6.4117913246154785,
      "learning_rate": 0.00011272727272727272,
      "loss": 1.1206,
      "step": 29
    },
    {
      "epoch": 0.005333333333333333,
      "grad_norm": 4.757745265960693,
      "learning_rate": 0.00010909090909090909,
      "loss": 0.8866,
      "step": 30
    },
    {
      "epoch": 0.005511111111111111,
      "grad_norm": 1.8826178312301636,
      "learning_rate": 0.00010545454545454545,
      "loss": 0.4887,
      "step": 31
    },
    {
      "epoch": 0.005688888888888889,
      "grad_norm": 2.5614876747131348,
      "learning_rate": 0.00010181818181818181,
      "loss": 0.6494,
      "step": 32
    },
    {
      "epoch": 0.005866666666666667,
      "grad_norm": 1.5820640325546265,
      "learning_rate": 9.818181818181818e-05,
      "loss": 0.3372,
      "step": 33
    },
    {
      "epoch": 0.006044444444444444,
      "grad_norm": 2.463679075241089,
      "learning_rate": 9.454545454545455e-05,
      "loss": 0.5345,
      "step": 34
    },
    {
      "epoch": 0.006222222222222222,
      "grad_norm": 2.917966365814209,
      "learning_rate": 9.090909090909092e-05,
      "loss": 0.461,
      "step": 35
    },
    {
      "epoch": 0.0064,
      "grad_norm": 5.302598476409912,
      "learning_rate": 8.727272727272727e-05,
      "loss": 0.8353,
      "step": 36
    },
    {
      "epoch": 0.006577777777777778,
      "grad_norm": 3.2318172454833984,
      "learning_rate": 8.363636363636364e-05,
      "loss": 0.6269,
      "step": 37
    },
    {
      "epoch": 0.0067555555555555554,
      "grad_norm": 5.365879058837891,
      "learning_rate": 8e-05,
      "loss": 0.9548,
      "step": 38
    },
    {
      "epoch": 0.006933333333333333,
      "grad_norm": 3.4723033905029297,
      "learning_rate": 7.636363636363637e-05,
      "loss": 0.7833,
      "step": 39
    },
    {
      "epoch": 0.0071111111111111115,
      "grad_norm": 2.9069981575012207,
      "learning_rate": 7.272727272727273e-05,
      "loss": 0.7734,
      "step": 40
    },
    {
      "epoch": 0.007288888888888889,
      "grad_norm": 4.312077522277832,
      "learning_rate": 6.90909090909091e-05,
      "loss": 1.0228,
      "step": 41
    },
    {
      "epoch": 0.007466666666666667,
      "grad_norm": 1.7139841318130493,
      "learning_rate": 6.545454545454546e-05,
      "loss": 0.4753,
      "step": 42
    },
    {
      "epoch": 0.007644444444444444,
      "grad_norm": 1.0198405981063843,
      "learning_rate": 6.181818181818182e-05,
      "loss": 0.2607,
      "step": 43
    },
    {
      "epoch": 0.007822222222222222,
      "grad_norm": 1.3717832565307617,
      "learning_rate": 5.818181818181818e-05,
      "loss": 0.3734,
      "step": 44
    },
    {
      "epoch": 0.008,
      "grad_norm": 1.712241768836975,
      "learning_rate": 5.4545454545454546e-05,
      "loss": 0.4626,
      "step": 45
    },
    {
      "epoch": 0.008177777777777779,
      "grad_norm": 3.1614370346069336,
      "learning_rate": 5.090909090909091e-05,
      "loss": 0.6659,
      "step": 46
    },
    {
      "epoch": 0.008355555555555555,
      "grad_norm": 3.9685189723968506,
      "learning_rate": 4.7272727272727275e-05,
      "loss": 0.9161,
      "step": 47
    },
    {
      "epoch": 0.008533333333333334,
      "grad_norm": 1.9686640501022339,
      "learning_rate": 4.3636363636363636e-05,
      "loss": 0.4969,
      "step": 48
    },
    {
      "epoch": 0.00871111111111111,
      "grad_norm": 2.0185980796813965,
      "learning_rate": 4e-05,
      "loss": 0.4481,
      "step": 49
    },
    {
      "epoch": 0.008888888888888889,
      "grad_norm": 1.8596620559692383,
      "learning_rate": 3.6363636363636364e-05,
      "loss": 0.5267,
      "step": 50
    },
    {
      "epoch": 0.009066666666666667,
      "grad_norm": 2.5506467819213867,
      "learning_rate": 3.272727272727273e-05,
      "loss": 0.5261,
      "step": 51
    },
    {
      "epoch": 0.009244444444444444,
      "grad_norm": 2.235466480255127,
      "learning_rate": 2.909090909090909e-05,
      "loss": 0.6693,
      "step": 52
    },
    {
      "epoch": 0.009422222222222222,
      "grad_norm": 1.1731500625610352,
      "learning_rate": 2.5454545454545454e-05,
      "loss": 0.3604,
      "step": 53
    },
    {
      "epoch": 0.0096,
      "grad_norm": 2.576580762863159,
      "learning_rate": 2.1818181818181818e-05,
      "loss": 0.8841,
      "step": 54
    },
    {
      "epoch": 0.009777777777777778,
      "grad_norm": 1.7024493217468262,
      "learning_rate": 1.8181818181818182e-05,
      "loss": 0.6927,
      "step": 55
    },
    {
      "epoch": 0.009955555555555556,
      "grad_norm": 2.758636236190796,
      "learning_rate": 1.4545454545454545e-05,
      "loss": 0.5332,
      "step": 56
    },
    {
      "epoch": 0.010133333333333333,
      "grad_norm": 1.5200008153915405,
      "learning_rate": 1.0909090909090909e-05,
      "loss": 0.5081,
      "step": 57
    },
    {
      "epoch": 0.010311111111111111,
      "grad_norm": 1.6790519952774048,
      "learning_rate": 7.272727272727272e-06,
      "loss": 0.3516,
      "step": 58
    },
    {
      "epoch": 0.01048888888888889,
      "grad_norm": 2.2804858684539795,
      "learning_rate": 3.636363636363636e-06,
      "loss": 0.523,
      "step": 59
    },
    {
      "epoch": 0.010666666666666666,
      "grad_norm": 1.838356852531433,
      "learning_rate": 0.0,
      "loss": 0.4788,
      "step": 60
    }
  ],
  "logging_steps": 1,
  "max_steps": 60,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 1,
  "save_steps": 500,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": true
      },
      "attributes": {}
    }
  },
  "total_flos": 3455308801634304.0,
  "train_batch_size": 2,
  "trial_name": null,
  "trial_params": null
}
